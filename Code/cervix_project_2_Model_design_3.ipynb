{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2. Model design 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation - SMOTE \n",
    "(Synthetic Minority Oversampling Technique) to overcome the data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.metrics import SpecificityAtSensitivity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the original data\n",
    "df1=pd.read_csv(\"../Data/kag_risk_factors_cervical_cancer.csv\")\n",
    "\n",
    "#load the processed datasets:\n",
    "X_train=pd.read_csv(\"../Data/X_train_preprocessed.csv\")\n",
    "X_test=pd.read_csv(\"../Data/X_test_preprocessed.csv\")\n",
    "X_validate=pd.read_csv(\"../Data/X_validate_preprocessed.csv\")\n",
    "y_train=pd.read_csv(\"../Data/y_train_preprocessed.csv\")\n",
    "y_test=pd.read_csv(\"../Data/y_test_preprocessed.csv\")\n",
    "y_validate=pd.read_csv(\"../Data/y_validate_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to np:\n",
    "y_train_np=y_train.to_numpy()\n",
    "X_train_np=X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 615), (1, 615)]\n"
     ]
    }
   ],
   "source": [
    "#using SMOTE create a balanced train dataset:\n",
    "x_train_s, y_train_s = SMOTE(random_state=33).fit_resample(X_train_np, y_train_np.ravel())\n",
    "print(sorted(Counter(y_train_s).items()))\n",
    "\n",
    "# now I  have a training dataset perfectly balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1230, 31) (1230,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_s.shape, y_train_s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Decission Tree Classifier and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_final = [] #--> New list for storing metrics of base models\n",
    "\n",
    "def models_dt(x,y,x_test,y_test):\n",
    "    mod = {}\n",
    "    model = DecisionTreeClassifier().fit(x,y)\n",
    "    ypred = model.predict(x_test)\n",
    "    mod['Model'] = 'Decision Tree After Sampling'\n",
    "    mod['Train_Score'] = model.score(x_train_s,y_train_s)\n",
    "    mod['Test_accuracy'] = metrics.accuracy_score(y_test,ypred)\n",
    "    mod['f1score'] = metrics.f1_score(y_test,ypred)\n",
    "    mod['recall'] = metrics.recall_score(y_test, ypred)\n",
    "    mod['precision'] = metrics.precision_score(y_test, ypred)\n",
    "    model.predict_proba(x_test)\n",
    "    mod['roc_auc'] = metrics.roc_auc_score(y_test,ypred)\n",
    "    return mod\n",
    "l_final.append(models_dt(x_train_s,y_train_s,X_test,y_test))\n",
    "\n",
    "def models_rf(x,y, x_test, y_test):\n",
    "    mod = {}\n",
    "    model = RandomForestClassifier().fit(x,y)\n",
    "    ypred = model.predict(x_test)\n",
    "    mod['Model'] = 'Random Forest After Sampling'\n",
    "    mod['Train_Score'] = model.score(x_train_s,y_train_s)\n",
    "    mod['Test_accuracy'] = metrics.accuracy_score(y_test,ypred)\n",
    "    mod['f1score'] = metrics.f1_score(y_test,ypred)\n",
    "    mod['recall'] = metrics.recall_score(y_test, ypred)\n",
    "    mod['precision'] = metrics.precision_score(y_test, ypred)\n",
    "    model.predict_proba(x_test)\n",
    "    mod['roc_auc'] = metrics.roc_auc_score(y_test,ypred)\n",
    "    return mod\n",
    "l_final.append(models_rf(x_train_s,y_train_s, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>Test_accuracy</th>\n",
       "      <th>f1score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree After Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.768432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest After Sampling</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.819315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Train_Score  Test_accuracy   f1score  \\\n",
       "0  Decision Tree After Sampling          1.0       0.948276  0.625000   \n",
       "1  Random Forest After Sampling          1.0       0.948276  0.666667   \n",
       "\n",
       "     recall  precision   roc_auc  \n",
       "0  0.555556   0.714286  0.768432  \n",
       "1  0.666667   0.666667  0.819315  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = pd.DataFrame(l_final)\n",
    "final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is 0.66 with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the neural network model from \"cervix_project_2_Model_design_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 800)               25600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 667,201\n",
      "Trainable params: 667,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "31/31 - 1s - loss: 0.4135 - precision_1: 0.7958 - recall_1: 0.7182 - accuracy: 0.8252 - val_loss: 0.2278 - val_precision_1: 1.0000 - val_recall_1: 0.9431 - val_accuracy: 0.9431\n",
      "Epoch 2/30\n",
      "31/31 - 0s - loss: 0.1225 - precision_1: 0.9514 - recall_1: 0.9539 - accuracy: 0.9644 - val_loss: 0.1093 - val_precision_1: 1.0000 - val_recall_1: 0.9634 - val_accuracy: 0.9634\n",
      "Epoch 3/30\n",
      "31/31 - 0s - loss: 0.0908 - precision_1: 0.9572 - recall_1: 0.9702 - accuracy: 0.9726 - val_loss: 0.0627 - val_precision_1: 1.0000 - val_recall_1: 0.9837 - val_accuracy: 0.9837\n",
      "Epoch 4/30\n",
      "31/31 - 0s - loss: 0.0703 - precision_1: 0.9631 - recall_1: 0.9892 - accuracy: 0.9817 - val_loss: 0.0363 - val_precision_1: 1.0000 - val_recall_1: 0.9919 - val_accuracy: 0.9919\n",
      "Epoch 5/30\n",
      "31/31 - 0s - loss: 0.0595 - precision_1: 0.9682 - recall_1: 0.9892 - accuracy: 0.9837 - val_loss: 0.0679 - val_precision_1: 1.0000 - val_recall_1: 0.9878 - val_accuracy: 0.9878\n",
      "Epoch 6/30\n",
      "31/31 - 0s - loss: 0.0543 - precision_1: 0.9707 - recall_1: 0.9864 - accuracy: 0.9837 - val_loss: 0.0652 - val_precision_1: 1.0000 - val_recall_1: 0.9878 - val_accuracy: 0.9878\n",
      "Epoch 7/30\n",
      "31/31 - 0s - loss: 0.0450 - precision_1: 0.9733 - recall_1: 0.9864 - accuracy: 0.9848 - val_loss: 0.0266 - val_precision_1: 1.0000 - val_recall_1: 0.9919 - val_accuracy: 0.9919\n",
      "Epoch 8/30\n",
      "31/31 - 0s - loss: 0.0455 - precision_1: 0.9735 - recall_1: 0.9946 - accuracy: 0.9878 - val_loss: 0.0211 - val_precision_1: 1.0000 - val_recall_1: 0.9919 - val_accuracy: 0.9919\n",
      "Epoch 9/30\n",
      "31/31 - 0s - loss: 0.0365 - precision_1: 0.9813 - recall_1: 0.9946 - accuracy: 0.9909 - val_loss: 0.0295 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "31/31 - 0s - loss: 0.0368 - precision_1: 0.9812 - recall_1: 0.9919 - accuracy: 0.9898 - val_loss: 0.0133 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "31/31 - 0s - loss: 0.0424 - precision_1: 0.9733 - recall_1: 0.9892 - accuracy: 0.9858 - val_loss: 0.0059 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "31/31 - 0s - loss: 0.0418 - precision_1: 0.9735 - recall_1: 0.9973 - accuracy: 0.9888 - val_loss: 0.0218 - val_precision_1: 1.0000 - val_recall_1: 0.9919 - val_accuracy: 0.9919\n",
      "Epoch 13/30\n",
      "31/31 - 0s - loss: 0.0327 - precision_1: 0.9813 - recall_1: 0.9973 - accuracy: 0.9919 - val_loss: 0.0193 - val_precision_1: 1.0000 - val_recall_1: 0.9959 - val_accuracy: 0.9959\n",
      "Epoch 14/30\n",
      "31/31 - 0s - loss: 0.0287 - precision_1: 0.9813 - recall_1: 0.9973 - accuracy: 0.9919 - val_loss: 0.0119 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "31/31 - 0s - loss: 0.0299 - precision_1: 0.9840 - recall_1: 0.9973 - accuracy: 0.9929 - val_loss: 0.0240 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "31/31 - 0s - loss: 0.0251 - precision_1: 0.9840 - recall_1: 0.9973 - accuracy: 0.9929 - val_loss: 0.0155 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "31/31 - 0s - loss: 0.0233 - precision_1: 0.9813 - recall_1: 0.9973 - accuracy: 0.9919 - val_loss: 0.0283 - val_precision_1: 1.0000 - val_recall_1: 0.9959 - val_accuracy: 0.9959\n",
      "Epoch 18/30\n",
      "31/31 - 0s - loss: 0.0196 - precision_1: 0.9892 - recall_1: 0.9973 - accuracy: 0.9949 - val_loss: 0.0026 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "31/31 - 0s - loss: 0.0216 - precision_1: 0.9866 - recall_1: 0.9973 - accuracy: 0.9939 - val_loss: 0.0176 - val_precision_1: 1.0000 - val_recall_1: 0.9959 - val_accuracy: 0.9959\n",
      "Epoch 20/30\n",
      "31/31 - 0s - loss: 0.0214 - precision_1: 0.9866 - recall_1: 0.9973 - accuracy: 0.9939 - val_loss: 0.0173 - val_precision_1: 1.0000 - val_recall_1: 0.9959 - val_accuracy: 0.9959\n",
      "Epoch 21/30\n",
      "31/31 - 0s - loss: 0.0215 - precision_1: 0.9866 - recall_1: 0.9946 - accuracy: 0.9929 - val_loss: 0.0123 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "31/31 - 0s - loss: 0.0224 - precision_1: 0.9839 - recall_1: 0.9946 - accuracy: 0.9919 - val_loss: 0.0046 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "31/31 - 0s - loss: 0.0143 - precision_1: 0.9892 - recall_1: 0.9973 - accuracy: 0.9949 - val_loss: 0.0049 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "31/31 - 0s - loss: 0.0184 - precision_1: 0.9893 - recall_1: 1.0000 - accuracy: 0.9959 - val_loss: 0.0079 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "31/31 - 0s - loss: 0.0145 - precision_1: 0.9919 - recall_1: 0.9973 - accuracy: 0.9959 - val_loss: 0.0060 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "31/31 - 0s - loss: 0.0151 - precision_1: 0.9892 - recall_1: 0.9973 - accuracy: 0.9949 - val_loss: 0.0037 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "31/31 - 0s - loss: 0.0195 - precision_1: 0.9866 - recall_1: 0.9973 - accuracy: 0.9939 - val_loss: 0.0211 - val_precision_1: 1.0000 - val_recall_1: 0.9919 - val_accuracy: 0.9919\n",
      "Epoch 28/30\n",
      "31/31 - 0s - loss: 0.0179 - precision_1: 0.9866 - recall_1: 0.9973 - accuracy: 0.9939 - val_loss: 0.0027 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "31/31 - 0s - loss: 0.0153 - precision_1: 0.9893 - recall_1: 1.0000 - accuracy: 0.9959 - val_loss: 0.0128 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "31/31 - 0s - loss: 0.0107 - precision_1: 0.9946 - recall_1: 0.9973 - accuracy: 0.9970 - val_loss: 0.0065 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "#Input layer\n",
    "model.add(Dense(units=800, \n",
    "            input_dim=31, # i have 31 features\n",
    "            kernel_initializer='uniform', # all features have the same weight\n",
    "            activation='relu'\n",
    "               ))\n",
    "model.add(Dropout(0.5))  #randomly sets 0.5 units to 0. To prevent overfitting\n",
    "#Hidden layer 1\n",
    "model.add(Dense(units=800,  \n",
    "                kernel_initializer='uniform', \n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(units=1, #only one unit needed, it its either 1 or not 1\n",
    "                kernel_initializer='uniform', \n",
    "                activation='sigmoid'))\n",
    "\n",
    "#model(output_bias=initial_bias)\n",
    "\n",
    "print(model.summary()) #for showing the structure and parameters\n",
    "\n",
    "# Defining how to measure performance\n",
    "model.compile(loss='binary_crossentropy',   \n",
    "              optimizer='adam',\n",
    "               metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),'accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# Verbose=2, showing loss and accuracy change timely\n",
    "#remove batch_size, the dataset is small. -> it increases recall.\n",
    "train_history = model.fit(x=x_train_s, y=y_train_s,  \n",
    "                          validation_split=0.2, epochs=30, verbose=2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6508 - precision_1: 0.7143 - recall_1: 0.5556 - accuracy: 0.9483\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is worse than with Random forest classifier (0.55 vs 0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use a fore strict feature selection to improve the recall, but porbably because of the small sample size and the imbalanced dataset these numbers cannot be improved much more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
